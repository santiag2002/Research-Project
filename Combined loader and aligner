#!/usr/bin/env nextflow

nextflow.enable.dsl = 2

// Parameters
params.project_dir = "$SCRATCH/Research_Project/Pipeline_dev"
params.accessions = "${params.project_dir}/accessions.csv"
params.outdir = "${params.project_dir}/results"
params.genome = "${params.project_dir}/reference_genome.fa"
params.genome_index_dir = "${params.project_dir}/genome_index"
params.genome_index_base = "genome_index"
params.temp_fastq = "${params.outdir}/temp_fastq"

// Variant calling parameters
params.min_coverage = 5
params.max_coverage = 100
params.min_mapping_quality = 20
params.min_base_quality = 20
params.max_missing = 0.1  // 90% present = 10% missing allowed
params.maf = 0.025        // 2.5% minor allele frequency

// Create channels
genome_ch = Channel.fromPath(params.genome)
genome_index_ch = Channel.fromPath("${params.genome_index_dir}/${params.genome_index_base}*.bt2")

// Process to download SRA data using native modules
process FETCHNGS {
    publishDir "${params.temp_fastq}", mode: 'copy'
    module 'StdEnv/2023:sra-toolkit/3.0.9'

    input:
    val accession

    output:
    tuple val(accession), path("*.fastq.gz"), emit: fastq_files

    script:
    """
    # Create NCBI config directory and settings
    mkdir -p ~/.ncbi
    cat > ~/.ncbi/user-settings.mkfg << 'EOF'
/LIBS/GUID = "726cb98a-eb6f-4d9c-88be-230f7dae3aec"
/libs/cloud/report_instance_identity = "true"
EOF

    # Download and compress
    fasterq-dump ${accession} --split-files
    gzip *.fastq
    """
}

// Align reads and sort
process ALIGN_AND_SORT {
    tag "$sample_id"
    publishDir "${params.outdir}/aligned", mode: 'copy'

    module 'StdEnv/2023:bowtie2/2.5.4:samtools/1.22.1'  // ← UPDATED WITH CORRECT VERSIONS

    input:
    tuple val(sample_id), val(is_paired), path(reads)
    each path(genome)
    each path(index)

    output:
    tuple val(sample_id), path("${sample_id}.bam"), path("${sample_id}.bam.bai"), emit: bam

    script:
    def reads_command = is_paired ? "-1 ${reads[0]} -2 ${reads[1]}" : "-U ${reads[0]}"
    """
    bowtie2 -p ${task.cpus} -x ${params.genome_index_dir}/${params.genome_index_base} ${reads_command} | \
    samtools view -bS - | \
    samtools sort -@ ${task.cpus} -o ${sample_id}.bam -
    samtools index ${sample_id}.bam
    """
}

// Generate depth
process SAMTOOLS_DEPTH {
    tag "$sample_id"
    publishDir "${params.outdir}/depth", mode: 'copy'

    module 'StdEnv/2023:samtools/1.22.1'  // ← UPDATED WITH CORRECT VERSION

    input:
    tuple val(sample_id), path(bam), path(bai)

    output:
    tuple val(sample_id), path("${sample_id}_depth.txt")

    script:
    """
    samtools depth ${bam} > ${sample_id}_depth.txt
    """
}

// Call variants using bcftools mpileup
process BCFTOOLS_MPILEUP {
    tag "variant_calling"
    publishDir "${params.outdir}/variants", mode: 'copy'

    module 'StdEnv/2023:bcftools/1.22'  // ← UPDATED WITH CORRECT VERSION

    input:
    path bam_files
    path bai_files
    path genome

    output:
    path "raw_variants.vcf.gz", emit: raw_vcf
    path "raw_variants.vcf.gz.csi", emit: raw_vcf_index

    script:
    def bam_list = bam_files.collect().join(' ')
    """
    # Create list of BAM files
    echo "${bam_list}" | tr ' ' '\\n' > bam_list.txt

    # Run bcftools mpileup and call
    bcftools mpileup \\
        -f ${genome} \\
        -b bam_list.txt \\
        -q ${params.min_mapping_quality} \\
        -Q ${params.min_base_quality} \\
        -a FORMAT/DP,FORMAT/AD \\
        -O u | \\
    bcftools call \\
        -m \\
        -v \\
        -O z \\
        -o raw_variants.vcf.gz

    # Index the VCF file
    bcftools index raw_variants.vcf.gz
    """
}

// Filter variants based on quality and population criteria
process FILTER_VARIANTS {
    tag "filter_variants"
    publishDir "${params.outdir}/variants", mode: 'copy'

    module 'StdEnv/2023:bcftools/1.22'  // ← UPDATED WITH CORRECT VERSION

    input:
    path raw_vcf
    path raw_vcf_index

    output:
    path "filtered_variants.vcf.gz", emit: filtered_vcf
    path "filtered_variants.vcf.gz.csi", emit: filtered_vcf_index
    path "variant_stats.txt", emit: stats

    script:
    """
    # Apply initial quality filters
    bcftools filter \\
        -i "QUAL>=20 && INFO/DP>=${params.min_coverage} && INFO/DP<=${params.max_coverage}" \\
        -O z \\
        -o quality_filtered.vcf.gz \\
        ${raw_vcf}

    bcftools index quality_filtered.vcf.gz

    # Apply population-level filters (90% present, MAF >= 2.5%)
    bcftools filter \\
        -i "F_MISSING<=${params.max_missing} && MAF>=${params.maf}" \\
        -O z \\
        -o filtered_variants.vcf.gz \\
        quality_filtered.vcf.gz

    bcftools index filtered_variants.vcf.gz

    # Generate statistics
    echo "Variant filtering statistics:" > variant_stats.txt
    echo "Raw variants: \$(bcftools view -H ${raw_vcf} | wc -l)" >> variant_stats.txt
    echo "Quality filtered: \$(bcftools view -H quality_filtered.vcf.gz | wc -l)" >> variant_stats.txt
    echo "Final filtered: \$(bcftools view -H filtered_variants.vcf.gz | wc -l)" >> variant_stats.txt
    echo "Samples: \$(bcftools query -l filtered_variants.vcf.gz | wc -l)" >> variant_stats.txt
    """
}

// Generate variant summary statistics
process VARIANT_STATS {
    tag "variant_statistics"
    publishDir "${params.outdir}/variants", mode: 'copy'

    module 'StdEnv/2023:bcftools/1.22'  // ← UPDATED WITH CORRECT VERSION

    input:
    path filtered_vcf
    path filtered_vcf_index

    output:
    path "variant_summary.txt"
    path "allele_frequencies.txt"

    script:
    """
    # Basic variant statistics
    bcftools stats ${filtered_vcf} > variant_summary.txt

    # Extract allele frequencies
    bcftools query -f '%CHROM\\t%POS\\t%REF\\t%ALT\\t%INFO/AF\\n' ${filtered_vcf} > allele_frequencies.txt
    """
}

// Define workflow
workflow {
    // Create genome channels
    genome_ch = Channel.fromPath(params.genome)
    genome_index_ch = Channel.fromPath("${params.genome_index_dir}/${params.genome_index_base}*")
        .collect()

    // Create accession channel
    accession_ch = Channel
        .fromPath(params.accessions)
        .splitCsv(header:true)
        .map { row -> row.accession }

    // Download samples
    fastq_files = FETCHNGS(accession_ch)

    // FIXED: Handle both single files and lists of files
    fastq_ch = fastq_files.fastq_files
        .map { accession, files ->
            // Convert single file to list if needed
            def file_list = files instanceof List ? files : [files]
            def sorted_files = file_list.sort { it.getName() }
            def is_paired = sorted_files.size() > 1
            [accession, is_paired, sorted_files]
        }

    // Continue with rest of pipeline
    aligned = ALIGN_AND_SORT(fastq_ch, genome_ch, genome_index_ch)
    depth = SAMTOOLS_DEPTH(aligned.bam)

    bam_files = aligned.bam.map { sample_id, bam, bai -> bam }.collect()
    bai_files = aligned.bam.map { sample_id, bam, bai -> bai }.collect()

    variants = BCFTOOLS_MPILEUP(bam_files, bai_files, genome_ch)
    filtered_variants = FILTER_VARIANTS(variants.raw_vcf, variants.raw_vcf_index)
    VARIANT_STATS(filtered_variants.filtered_vcf, filtered_variants.filtered_vcf_index)
}
